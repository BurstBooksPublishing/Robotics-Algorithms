import numpy as np
from scipy.spatial.distance import euclidean
from fastdtw import fastdtw  # Efficient DTW implementation

def preprocess_gesture_data(gesture_sequence):
    """
    Normalize and smooth a gesture sequence (e.g., from motion capture or IMU).
    Args:
        gesture_sequence: Numpy array of shape (n_frames, n_features)
    Returns:
        Normalized and smoothed sequence
    """
    # Min-max normalization per feature dimension
    norm_sequence = (gesture_sequence - np.min(gesture_sequence, axis=0)) / \
                   (np.max(gesture_sequence, axis=0) - np.min(gesture_sequence, axis=0) + 1e-8)
    # Simple moving average smoothing
    window_size = 3
    smoothed_sequence = np.convolve(norm_sequence.flatten(), np.ones(window_size)/window_size, mode='same')
    return smoothed_sequence.reshape(gesture_sequence.shape)

def compute_dtw_distance(seq1, seq2):
    """
    Compute DTW distance between two gesture sequences.
    Args:
        seq1, seq2: Numpy arrays of shape (n_frames, n_features)
    Returns:
        DTW distance and alignment path
    """
    distance, path = fastdtw(seq1, seq2, dist=euclidean)
    return distance, path

class GestureRecognizer:
    def __init__(self, template_gestures):
        """
        Initialize with template gestures for comparison.
        Args:
            template_gestures: Dict of {gesture_name: normalized_sequence}
        """
        self.templates = template_gestures

    def recognize_gesture(self, input_sequence):
        """
        Recognize gesture by comparing with templates using DTW.
        Args:
            input_sequence: Raw input sequence to classify
        Returns:
            Tuple of (recognized_gesture_name, min_distance, alignment_path)
        """
        processed_input = preprocess_gesture_data(input_sequence)
        min_distance = float('inf')
        recognized_gesture = None
        best_path = None

        for name, template in self.templates.items():
            distance, path = compute_dtw_distance(template, processed_input)
            if distance < min_distance:
                min_distance = distance
                recognized_gesture = name
                best_path = path

        return recognized_gesture, min_distance, best_path

# Example usage
if __name__ == "__main__":
    # Mock template gestures (in practice, these would be pre-recorded)
    templates = {
        "wave": np.random.rand(30, 3),  # 30 frames, 3D coordinates
        "circle": np.random.rand(40, 3),
        "grab": np.random.rand(25, 3)
    }

    # Normalize templates
    normalized_templates = {name: preprocess_gesture_data(seq) for name, seq in templates.items()}
    recognizer = GestureRecognizer(normalized_templates)

    # Simulate input gesture (would come from sensors in real application)
    test_gesture = np.random.rand(35, 3)
    gesture_name, distance, path = recognizer.recognize_gesture(test_gesture)

    print(f"Recognized gesture: {gesture_name}, DTW distance: {distance:.2f}")